# ç¨‹åºå‘˜è¯­éŸ³æ¨¡å‹é€‰æ‹©æŒ‡å—

## ğŸ¯ æ¦‚è¿°

æœ¬æŒ‡å—å±•ç¤ºç¨‹åºå‘˜å¦‚ä½•åœ¨ä»£ç ä¸­è‡ªç”±é€‰æ‹©STTï¼ˆè¯­éŸ³è½¬æ–‡æœ¬ï¼‰å’ŒTTSï¼ˆæ–‡æœ¬è½¬è¯­éŸ³ï¼‰æ¨¡å‹ï¼Œè€Œä¸æ˜¯é€šè¿‡é…ç½®æ–‡ä»¶è®©ç”¨æˆ·é€‰æ‹©ã€‚

## ğŸ”§ æ¨¡å‹é€‰æ‹©æ–¹å¼

### 1. ç›´æ¥å®ä¾‹åŒ–æ¨¡å‹

```python
from voice_interface import WhisperSTT, GummySTT, EdgeTTS, Pyttsx3TTS

# é€‰æ‹©STTæ¨¡å‹
stt = WhisperSTT(model_size="base")  # æˆ– GummySTT, SpeechRecognitionSTT

# é€‰æ‹©TTSæ¨¡å‹  
tts = EdgeTTS(voice="zh-CN-XiaoxiaoNeural")  # æˆ– Pyttsx3TTS

# åˆ›å»ºè¯­éŸ³æ¥å£
voice = VoiceInterface(stt_model=stt, tts_model=tts)
```

### 2. åœ¨RAGç³»ç»Ÿä¸­é€‰æ‹©æ¨¡å‹

```python
# åœ¨ multimodal_rag.py çš„ _create_voice_interface æ–¹æ³•ä¸­
def _create_voice_interface(self) -> VoiceInterface:
    # æ–¹æ¡ˆ1: é«˜è´¨é‡ç»„åˆ (ç”Ÿäº§ç¯å¢ƒ)
    stt = GummySTT(api_key=os.getenv("DASHSCOPE_API_KEY"))
    tts = EdgeTTS(voice="zh-CN-XiaoxiaoNeural")
    return VoiceInterface(stt_model=stt, tts_model=tts)
    
    # æ–¹æ¡ˆ2: æœ¬åœ°å¤„ç†ç»„åˆ (éšç§æ•æ„Ÿ)
    # stt = WhisperSTT(model_size="base")
    # tts = Pyttsx3TTS(rate=200, volume=0.9)
    # return VoiceInterface(stt_model=stt, tts_model=tts)
```

## ğŸ“Š æ¨¡å‹ç»„åˆæ¨è

### ğŸ† é«˜è´¨é‡ç»„åˆ (ç”Ÿäº§ç¯å¢ƒ)
```python
# æœ€ä½³è¯†åˆ«è´¨é‡ + æœ€ä½³è¯­éŸ³åˆæˆ
stt = GummySTT(api_key="your-api-key")  # é˜¿é‡Œäº‘é«˜è´¨é‡è¯†åˆ«
tts = EdgeTTS(voice="zh-CN-XiaoxiaoNeural")  # å¾®è½¯è‡ªç„¶è¯­éŸ³
```
**ä¼˜åŠ¿**: è¯†åˆ«å‡†ç¡®ç‡é«˜ï¼Œè¯­éŸ³è‡ªç„¶æµç•…  
**é€‚ç”¨**: ç”Ÿäº§ç¯å¢ƒã€å•†ä¸šåº”ç”¨

### ğŸ”’ æœ¬åœ°å¤„ç†ç»„åˆ (éšç§æ•æ„Ÿ)
```python
# å®Œå…¨æœ¬åœ°å¤„ç†ï¼Œæ•°æ®ä¸ä¸Šä¼ 
stt = WhisperSTT(model_size="base")  # æœ¬åœ°Whisper
tts = Pyttsx3TTS(rate=200, volume=0.9)  # ç³»ç»ŸTTS
```
**ä¼˜åŠ¿**: æ•°æ®éšç§å®‰å…¨ï¼Œç¦»çº¿å¯ç”¨  
**é€‚ç”¨**: ä¼ä¸šå†…éƒ¨ã€éšç§æ•æ„Ÿåœºæ™¯

### âš¡ å¿«é€ŸåŸå‹ç»„åˆ (å¼€å‘æµ‹è¯•)
```python
# å¿«é€Ÿéƒ¨ç½²ï¼Œæ˜“äºè°ƒè¯•
stt = SpeechRecognitionSTT(engine="google")  # ç®€å•æ˜“ç”¨
tts = EdgeTTS(voice="zh-CN-XiaoxiaoNeural")  # äº‘ç«¯TTS
```
**ä¼˜åŠ¿**: éƒ¨ç½²ç®€å•ï¼Œè°ƒè¯•æ–¹ä¾¿  
**é€‚ç”¨**: åŸå‹å¼€å‘ã€å¿«é€Ÿæµ‹è¯•

## ğŸ›ï¸ è¯¦ç»†é…ç½®é€‰é¡¹

### STTæ¨¡å‹é…ç½®

#### Whisper STT
```python
# æ¨¡å‹å¤§å°é€‰æ‹©
stt = WhisperSTT(model_size="tiny")    # æœ€å¿«ï¼Œç²¾åº¦è¾ƒä½
stt = WhisperSTT(model_size="base")    # å¹³è¡¡
stt = WhisperSTT(model_size="small")   # è¾ƒå¥½ç²¾åº¦
stt = WhisperSTT(model_size="medium")  # é«˜ç²¾åº¦
stt = WhisperSTT(model_size="large")   # æœ€é«˜ç²¾åº¦ï¼Œæœ€æ…¢
```

#### é˜¿é‡Œäº‘Gummy STT
```python
# éœ€è¦API Key
stt = GummySTT(
    api_key="your-dashscope-api-key",
    model="gummy-chat-v1"
)
```

#### SpeechRecognition STT
```python
# å¼•æ“é€‰æ‹©
stt = SpeechRecognitionSTT(engine="google")  # Googleè¯†åˆ«
stt = SpeechRecognitionSTT(engine="sphinx")   # æœ¬åœ°Sphinx
```

### TTSæ¨¡å‹é…ç½®

#### Edge TTS
```python
# ä¸­æ–‡è¯­éŸ³é€‰æ‹©
tts = EdgeTTS(voice="zh-CN-XiaoxiaoNeural")  # å¥³å£°ï¼Œæ¸©æŸ”
tts = EdgeTTS(voice="zh-CN-YunxiNeural")    # ç”·å£°ï¼Œæ²‰ç¨³
tts = EdgeTTS(voice="zh-CN-YunyangNeural")  # ç”·å£°ï¼Œä¸“ä¸š
```

#### Pyttsx3 TTS
```python
# ç³»ç»Ÿå†…ç½®TTS
tts = Pyttsx3TTS(
    rate=200,      # è¯­é€Ÿ (50-300)
    volume=0.9     # éŸ³é‡ (0.0-1.0)
)
```

## ğŸš€ å®é™…ä½¿ç”¨ç¤ºä¾‹

### ç¤ºä¾‹1: ç”Ÿäº§ç¯å¢ƒé…ç½®
```python
# åœ¨ multimodal_rag.py ä¸­
def _create_voice_interface(self) -> VoiceInterface:
    # ç”Ÿäº§ç¯å¢ƒï¼šé«˜è´¨é‡è¯†åˆ« + è‡ªç„¶è¯­éŸ³
    api_key = os.getenv("DASHSCOPE_API_KEY")
    if api_key:
        stt = GummySTT(api_key=api_key)
        tts = EdgeTTS(voice="zh-CN-XiaoxiaoNeural")
    else:
        # å¤‡é€‰æ–¹æ¡ˆ
        stt = WhisperSTT(model_size="base")
        tts = EdgeTTS(voice="zh-CN-XiaoxiaoNeural")
    
    return VoiceInterface(stt_model=stt, tts_model=tts)
```

### ç¤ºä¾‹2: å¼€å‘ç¯å¢ƒé…ç½®
```python
# å¼€å‘ç¯å¢ƒï¼šå¿«é€Ÿéƒ¨ç½²
def _create_voice_interface(self) -> VoiceInterface:
    stt = SpeechRecognitionSTT(engine="google")
    tts = EdgeTTS(voice="zh-CN-XiaoxiaoNeural")
    return VoiceInterface(stt_model=stt, tts_model=tts)
```

### ç¤ºä¾‹3: éšç§æ•æ„Ÿé…ç½®
```python
# éšç§æ•æ„Ÿï¼šå®Œå…¨æœ¬åœ°å¤„ç†
def _create_voice_interface(self) -> VoiceInterface:
    stt = WhisperSTT(model_size="base")
    tts = Pyttsx3TTS(rate=200, volume=0.9)
    return VoiceInterface(stt_model=stt, tts_model=tts)
```

## ğŸ”„ åŠ¨æ€æ¨¡å‹åˆ‡æ¢

```python
# æ ¹æ®æ¡ä»¶åŠ¨æ€é€‰æ‹©æ¨¡å‹
def create_voice_interface(environment="production"):
    if environment == "production":
        stt = GummySTT(api_key=os.getenv("DASHSCOPE_API_KEY"))
        tts = EdgeTTS(voice="zh-CN-XiaoxiaoNeural")
    elif environment == "development":
        stt = SpeechRecognitionSTT(engine="google")
        tts = EdgeTTS(voice="zh-CN-XiaoxiaoNeural")
    else:  # local
        stt = WhisperSTT(model_size="base")
        tts = Pyttsx3TTS(rate=200, volume=0.9)
    
    return VoiceInterface(stt_model=stt, tts_model=tts)
```

## ğŸ“ æœ€ä½³å®è·µ

1. **ç”Ÿäº§ç¯å¢ƒ**: ä½¿ç”¨Gummy STT + Edge TTS
2. **å¼€å‘ç¯å¢ƒ**: ä½¿ç”¨SpeechRecognition STT + Edge TTS  
3. **éšç§æ•æ„Ÿ**: ä½¿ç”¨Whisper STT + Pyttsx3 TTS
4. **æ€§èƒ½ä¼˜å…ˆ**: ä½¿ç”¨Whisper tiny + Pyttsx3 TTS
5. **è´¨é‡ä¼˜å…ˆ**: ä½¿ç”¨Gummy STT + Edge TTS

## ğŸ› ï¸ è¿è¡Œç¤ºä¾‹

```bash
# è¿è¡Œè¯­éŸ³æ¨¡å‹é€‰æ‹©ç¤ºä¾‹
python voice_examples.py

# è¿è¡Œå¤šæ¨¡æ€RAGï¼ˆä½¿ç”¨ç¨‹åºå‘˜é€‰æ‹©çš„æ¨¡å‹ï¼‰
python multimodal_rag.py
```

## ğŸ’¡ æ€»ç»“

ç¨‹åºå‘˜å¯ä»¥é€šè¿‡ä»¥ä¸‹æ–¹å¼é€‰æ‹©è¯­éŸ³æ¨¡å‹ï¼š

1. **ç›´æ¥å®ä¾‹åŒ–**: `VoiceInterface(stt_model=stt, tts_model=tts)`
2. **ä¿®æ”¹ä»£ç **: åœ¨ `_create_voice_interface()` æ–¹æ³•ä¸­é€‰æ‹©
3. **åŠ¨æ€é€‰æ‹©**: æ ¹æ®ç¯å¢ƒæˆ–æ¡ä»¶åŠ¨æ€é€‰æ‹©æ¨¡å‹
4. **ç»„åˆä½¿ç”¨**: ä¸åŒåœºæ™¯ä½¿ç”¨ä¸åŒçš„æ¨¡å‹ç»„åˆ

è¿™æ ·ç¨‹åºå‘˜å¯ä»¥å®Œå…¨æ§åˆ¶è¯­éŸ³æ¨¡å‹çš„é€‰æ‹©ï¼Œè€Œä¸éœ€è¦ç”¨æˆ·é€šè¿‡é…ç½®æ–‡ä»¶æ¥é€‰æ‹©ã€‚
