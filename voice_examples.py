"""
è¯­éŸ³æ¨¡å‹é€‰æ‹©ç¤ºä¾‹ - å±•ç¤ºç¨‹åºå‘˜å¦‚ä½•è‡ªç”±é€‰æ‹©STTå’ŒTTSæ¨¡å‹
"""
import os
from dotenv import load_dotenv
from voice_interface import (
    VoiceInterface, 
    WhisperSTT, 
    GummySTT, 
    SpeechRecognitionSTT,
    EdgeTTS, 
    Pyttsx3TTS
)

def example_1_whisper_edge():
    """ç¤ºä¾‹1: Whisper STT + Edge TTS"""
    print("=== ç¤ºä¾‹1: Whisper STT + Edge TTS ===")
    
    # ç¨‹åºå‘˜é€‰æ‹©æ¨¡å‹
    stt = WhisperSTT(model_size="base")  # é€‰æ‹©Whisper baseæ¨¡å‹
    tts = EdgeTTS(voice="zh-CN-XiaoxiaoNeural")  # é€‰æ‹©Edge TTSä¸­æ–‡è¯­éŸ³
    
    # åˆ›å»ºè¯­éŸ³æ¥å£
    voice = VoiceInterface(stt_model=stt, tts_model=tts)
    
    # æµ‹è¯•è¯­éŸ³è½¬æ–‡æœ¬
    print("æµ‹è¯•è¯­éŸ³è½¬æ–‡æœ¬...")
    text = voice.voice_to_text(duration=3)
    print(f"è¯†åˆ«ç»“æœ: {text}")
    
    # æµ‹è¯•æ–‡æœ¬è½¬è¯­éŸ³
    if text.strip():
        print("æµ‹è¯•æ–‡æœ¬è½¬è¯­éŸ³...")
        voice.text_to_voice(text)
    
    voice.cleanup()


def example_2_gummy_pyttsx3():
    """ç¤ºä¾‹2: é˜¿é‡Œäº‘Gummy STT + Pyttsx3 TTS"""
    print("\n=== ç¤ºä¾‹2: é˜¿é‡Œäº‘Gummy STT + Pyttsx3 TTS ===")
    
    # éœ€è¦è®¾ç½®API Key
    api_key = os.getenv("DASHSCOPE_API_KEY")
    if not api_key:
        print("è¯·è®¾ç½®DASHSCOPE_API_KEYç¯å¢ƒå˜é‡")
        return
    
    # ç¨‹åºå‘˜é€‰æ‹©æ¨¡å‹
    stt = GummySTT(api_key=api_key, model="gummy-chat-v1")
    tts = Pyttsx3TTS(rate=200, volume=0.9)
    
    # åˆ›å»ºè¯­éŸ³æ¥å£
    voice = VoiceInterface(stt_model=stt, tts_model=tts)
    
    # æµ‹è¯•è¯­éŸ³è½¬æ–‡æœ¬
    print("æµ‹è¯•è¯­éŸ³è½¬æ–‡æœ¬...")
    text = voice.voice_to_text(duration=3)
    print(f"è¯†åˆ«ç»“æœ: {text}")
    
    # æµ‹è¯•æ–‡æœ¬è½¬è¯­éŸ³
    if text.strip():
        print("æµ‹è¯•æ–‡æœ¬è½¬è¯­éŸ³...")
        voice.text_to_voice(text)
    
    voice.cleanup()


def example_3_speech_recognition_edge():
    """ç¤ºä¾‹3: SpeechRecognition STT + Edge TTS"""
    print("\n=== ç¤ºä¾‹3: SpeechRecognition STT + Edge TTS ===")
    
    # ç¨‹åºå‘˜é€‰æ‹©æ¨¡å‹
    stt = SpeechRecognitionSTT(engine="google")
    tts = EdgeTTS(voice="zh-CN-YunxiNeural")  # é€‰æ‹©ä¸åŒçš„ä¸­æ–‡è¯­éŸ³
    
    # åˆ›å»ºè¯­éŸ³æ¥å£
    voice = VoiceInterface(stt_model=stt, tts_model=tts)
    
    # æµ‹è¯•è¯­éŸ³è½¬æ–‡æœ¬
    print("æµ‹è¯•è¯­éŸ³è½¬æ–‡æœ¬...")
    text = voice.voice_to_text(duration=3)
    print(f"è¯†åˆ«ç»“æœ: {text}")
    
    # æµ‹è¯•æ–‡æœ¬è½¬è¯­éŸ³
    if text.strip():
        print("æµ‹è¯•æ–‡æœ¬è½¬è¯­éŸ³...")
        voice.text_to_voice(text)
    
    voice.cleanup()


def example_4_custom_config():
    """ç¤ºä¾‹4: è‡ªå®šä¹‰é…ç½®çš„æ¨¡å‹é€‰æ‹©"""
    print("\n=== ç¤ºä¾‹4: è‡ªå®šä¹‰é…ç½® ===")
    
    # ç¨‹åºå‘˜å¯ä»¥æ ¹æ®éœ€æ±‚é€‰æ‹©ä¸åŒçš„æ¨¡å‹ç»„åˆ
    
    # é«˜è´¨é‡è¯†åˆ« + é«˜è´¨é‡è¯­éŸ³åˆæˆ
    print("é«˜è´¨é‡ç»„åˆ: Gummy STT + Edge TTS")
    api_key = os.getenv("DASHSCOPE_API_KEY")
    if api_key:
        stt_high = GummySTT(api_key=api_key)
        tts_high = EdgeTTS(voice="zh-CN-XiaoxiaoNeural")
        voice_high = VoiceInterface(stt_model=stt_high, tts_model=tts_high)
        print("é«˜è´¨é‡æ¨¡å‹å·²é…ç½®")
        voice_high.cleanup()
    
    # æœ¬åœ°å¤„ç† + ç³»ç»ŸTTS
    print("æœ¬åœ°å¤„ç†ç»„åˆ: Whisper STT + Pyttsx3 TTS")
    stt_local = WhisperSTT(model_size="tiny")  # ä½¿ç”¨æ›´å°çš„æ¨¡å‹
    tts_local = Pyttsx3TTS(rate=150, volume=0.8)
    voice_local = VoiceInterface(stt_model=stt_local, tts_model=tts_local)
    print("æœ¬åœ°å¤„ç†æ¨¡å‹å·²é…ç½®")
    voice_local.cleanup()
    
    # å¿«é€ŸåŸå‹ç»„åˆ
    print("å¿«é€ŸåŸå‹ç»„åˆ: SpeechRecognition STT + Edge TTS")
    stt_fast = SpeechRecognitionSTT(engine="google")
    tts_fast = EdgeTTS(voice="zh-CN-XiaoxiaoNeural")
    voice_fast = VoiceInterface(stt_model=stt_fast, tts_model=tts_fast)
    print("å¿«é€ŸåŸå‹æ¨¡å‹å·²é…ç½®")
    voice_fast.cleanup()


def example_5_rag_integration():
    """ç¤ºä¾‹5: ä¸RAGç³»ç»Ÿé›†æˆ"""
    print("\n=== ç¤ºä¾‹5: ä¸RAGç³»ç»Ÿé›†æˆ ===")
    
    # ç¨‹åºå‘˜ä¸ºRAGç³»ç»Ÿé€‰æ‹©æœ€é€‚åˆçš„è¯­éŸ³æ¨¡å‹
    # æ¨èç»„åˆï¼šé«˜è´¨é‡è¯†åˆ« + è‡ªç„¶è¯­éŸ³åˆæˆ
    
    # é€‰æ‹©æ¨¡å‹
    api_key = os.getenv("DASHSCOPE_API_KEY")
    if api_key:
        stt = GummySTT(api_key=api_key)  # é«˜è´¨é‡ä¸­æ–‡è¯†åˆ«
        tts = EdgeTTS(voice="zh-CN-XiaoxiaoNeural")  # è‡ªç„¶ä¸­æ–‡è¯­éŸ³
    else:
        stt = WhisperSTT(model_size="base")  # å¤‡é€‰æ–¹æ¡ˆ
        tts = EdgeTTS(voice="zh-CN-XiaoxiaoNeural")
    
    # åˆ›å»ºè¯­éŸ³æ¥å£
    voice = VoiceInterface(stt_model=stt, tts_model=tts)
    
    print("RAGè¯­éŸ³æ¥å£å·²é…ç½®:")
    print(f"STTæ¨¡å‹: {type(stt).__name__}")
    print(f"TTSæ¨¡å‹: {type(tts).__name__}")
    
    # è¿™é‡Œå¯ä»¥é›†æˆåˆ°RAGç³»ç»Ÿä¸­
    # from multimodal_rag import MultimodalRAG
    # rag = MultimodalRAG()
    # rag.voice = voice  # ä½¿ç”¨è‡ªå®šä¹‰çš„è¯­éŸ³æ¥å£
    
    voice.cleanup()


def main():
    """è¿è¡Œæ‰€æœ‰ç¤ºä¾‹"""
    load_dotenv()
    
    print("ğŸ™ï¸ è¯­éŸ³æ¨¡å‹é€‰æ‹©ç¤ºä¾‹")
    print("=" * 50)
    print("è¿™äº›ç¤ºä¾‹å±•ç¤ºç¨‹åºå‘˜å¦‚ä½•è‡ªç”±é€‰æ‹©STTå’ŒTTSæ¨¡å‹")
    print("=" * 50)
    
    try:
        # è¿è¡Œç¤ºä¾‹
        example_1_whisper_edge()
        example_2_gummy_pyttsx3()
        example_3_speech_recognition_edge()
        example_4_custom_config()
        example_5_rag_integration()
        
        print("\nâœ… æ‰€æœ‰ç¤ºä¾‹è¿è¡Œå®Œæˆï¼")
        print("\nğŸ’¡ ç¨‹åºå‘˜å¯ä»¥æ ¹æ®éœ€æ±‚é€‰æ‹©ä¸åŒçš„æ¨¡å‹ç»„åˆ:")
        print("- é«˜è´¨é‡: Gummy STT + Edge TTS")
        print("- æœ¬åœ°å¤„ç†: Whisper STT + Pyttsx3 TTS")
        print("- å¿«é€ŸåŸå‹: SpeechRecognition STT + Edge TTS")
        
    except Exception as e:
        print(f"âŒ ç¤ºä¾‹è¿è¡Œå¤±è´¥: {e}")
        print("è¯·ç¡®ä¿å·²å®‰è£…æ‰€éœ€çš„ä¾èµ–åŒ…")


if __name__ == "__main__":
    main()
