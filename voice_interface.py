"""
è¯­éŸ³æ¥å£æ¨¡å— - åªæ”¯æŒGummySTTå’Œqwen3-tts-flash
"""
import os
import io
import time
import logging
from typing import Optional, Dict, Any
from abc import ABC, abstractmethod

import pyaudio
import wave
import numpy as np
from dotenv import load_dotenv

# é˜¿é‡Œäº‘DashScopeå¯¼å…¥
try:
    import dashscope
    from dashscope.audio.asr import TranslationRecognizerChat, TranslationRecognizerCallback, TranscriptionResult, TranslationResult
    DASHSCOPE_AVAILABLE = True
except ImportError:
    DASHSCOPE_AVAILABLE = False

# WebSocketå¯¼å…¥
try:
    import websocket
    import json
    import threading
    import io
    WEBSOCKET_AVAILABLE = True
except ImportError:
    WEBSOCKET_AVAILABLE = False


class STTModel(ABC):
    """è¯­éŸ³è½¬æ–‡æœ¬åŸºç±»"""
    
    @abstractmethod
    def transcribe(self, audio_data: bytes) -> str:
        pass


class GummySTT(STTModel):
    """é˜¿é‡Œäº‘Gummyä¸€å¥è¯è¯†åˆ«STT"""
    
    def __init__(self, api_key: str = None, model: str = "gummy-chat-v1"):
        if not DASHSCOPE_AVAILABLE:
            raise ImportError("dashscope not installed. Run: pip install dashscope")
        
        # è®¾ç½®API Key
        if api_key:
            dashscope.api_key = api_key
        elif os.getenv("DASHSCOPE_API_KEY"):
            dashscope.api_key = os.getenv("DASHSCOPE_API_KEY")
        else:
            raise ValueError("DASHSCOPE_API_KEY not found. Please set it in environment or pass api_key parameter")
        
        self.model = model
        self.recognized_text = ""
        self.recognition_complete = False
        logging.info(f"Gummy STT initialized with model: {model}")
    
    def transcribe(self, audio_data: bytes) -> str:
        """ä½¿ç”¨Gummyè¿›è¡Œè¯­éŸ³è¯†åˆ«"""
        self.recognized_text = ""
        self.recognition_complete = False
        
        # åˆ›å»ºå›è°ƒç±»
        class GummyCallback(TranslationRecognizerCallback):
            def __init__(self, parent):
                self.parent = parent
            
            def on_open(self) -> None:
                logging.info("Gummy STT connection opened")
            
            def on_close(self) -> None:
                logging.info("Gummy STT connection closed")
            
            def on_event(self, request_id, transcription_result: TranscriptionResult, 
                        translation_result: TranslationResult, usage) -> None:
                if transcription_result is not None:
                    self.parent.recognized_text = transcription_result.text
                    if transcription_result.is_sentence_end:
                        self.parent.recognition_complete = True
                        logging.info(f"Gummy STT recognition complete: {self.parent.recognized_text}")
        
        # åˆ›å»ºè¯†åˆ«å™¨
        callback = GummyCallback(self)
        recognizer = TranslationRecognizerChat(
            model=self.model,
            format="pcm",
            sample_rate=16000,
            transcription_enabled=True,
            translation_enabled=False,  # åªåšè¯†åˆ«ï¼Œä¸åšç¿»è¯‘
            callback=callback,
        )
        
        try:
            # å¯åŠ¨è¯†åˆ«
            recognizer.start()
            
            # åˆ†å—å‘é€éŸ³é¢‘æ•°æ®
            chunk_size = 3200  # çº¦100msçš„éŸ³é¢‘æ•°æ®
            for i in range(0, len(audio_data), chunk_size):
                chunk = audio_data[i:i + chunk_size]
                if not recognizer.send_audio_frame(chunk):
                    break
                if self.recognition_complete:
                    break
            
            # åœæ­¢è¯†åˆ«
            recognizer.stop()
            
            return self.recognized_text.strip()
            
        except Exception as e:
            logging.error(f"Gummy STT recognition failed: {e}")
            return ""


class TTSModel(ABC):
    """æ–‡æœ¬è½¬è¯­éŸ³åŸºç±»"""
    
    @abstractmethod
    def synthesize(self, text: str) -> bytes:
        pass


class Qwen3TTSRealtime(TTSModel):
    """Qwen3 TTS Realtimeæ¨¡å‹ - ä½¿ç”¨WebSocketè¿æ¥"""
    
    def __init__(self, api_key: str = None, model: str = "qwen3-tts-flash-realtime"):
        if not WEBSOCKET_AVAILABLE:
            raise ImportError("websocket-client not installed. Run: pip install websocket-client")
        
        # è®¾ç½®API Key
        if api_key:
            self.api_key = api_key
        elif os.getenv("DASHSCOPE_API_KEY"):
            self.api_key = os.getenv("DASHSCOPE_API_KEY")
        else:
            raise ValueError("DASHSCOPE_API_KEY not found. Please set it in environment or pass api_key parameter")
        
        self.model = model
        self.api_url = f"wss://dashscope.aliyuncs.com/api-ws/v1/realtime?model={model}"
        self.audio_data = b""
        self.synthesis_complete = False
        logging.info(f"Qwen3 TTS Realtime initialized with model: {model}")
    
    def synthesize_streaming(self, text: str, voice: str = "Cherry", callback=None) -> dict:
        """ä½¿ç”¨Qwen3 TTS Realtimeè¿›è¡Œæµå¼è¯­éŸ³åˆæˆ"""
        try:
            self.audio_data = b""
            self.synthesis_complete = False
            self.first_audio_time = None
            self.synthesis_start_time = time.perf_counter()
            
            # åˆ›å»ºWebSocketè¿æ¥
            headers = [f"Authorization: Bearer {self.api_key}"]
            
            def on_open(ws):
                logging.info(f"Connected to TTS server: {self.api_url}")
                # å‘é€é…ç½®æ¶ˆæ¯ - æ ¹æ®å®˜æ–¹æ–‡æ¡£æ ¼å¼
                config_message = {
                    "type": "config",
                    "voice": voice,
                    "format": "wav",
                    "sample_rate": 16000,
                    "enable_timestamp": False
                }
                ws.send(json.dumps(config_message))
                
                # å‘é€æ–‡æœ¬æ¶ˆæ¯ - æ”¯æŒæµå¼è¾“å…¥
                text_message = {
                    "type": "text",
                    "text": text
                }
                ws.send(json.dumps(text_message))
                
                # å‘é€ç»“æŸæ¶ˆæ¯
                end_message = {
                    "type": "end"
                }
                ws.send(json.dumps(end_message))
            
            def on_message(ws, message):
                try:
                    data = json.loads(message)
                    logging.debug(f"Received message: {data}")
                    
                    # æ ¹æ®å®˜æ–¹æ–‡æ¡£å¤„ç†ä¸åŒç±»å‹çš„æ¶ˆæ¯
                    if data.get("type") == "audio":
                        # è®°å½•é¦–éŸ³é¢‘æ—¶é—´
                        if self.first_audio_time is None:
                            self.first_audio_time = time.perf_counter()
                            first_audio_latency = (self.first_audio_time - self.synthesis_start_time) * 1000.0
                            print(f"âš¡ è¯­éŸ³é¦–tokenå»¶è¿Ÿ: {first_audio_latency:.1f}ms")
                        
                        # è§£ç base64éŸ³é¢‘æ•°æ®
                        import base64
                        audio_chunk = base64.b64decode(data["audio"])
                        self.audio_data += audio_chunk
                        
                        # æµå¼æ’­æ”¾éŸ³é¢‘
                        if callback:
                            callback(audio_chunk)
                        
                        logging.debug(f"Received audio chunk: {len(audio_chunk)} bytes")
                    
                    elif data.get("type") == "audio.done":
                        # éŸ³é¢‘ç”Ÿæˆå®Œæˆ
                        logging.info("Audio generation completed")
                    
                    elif data.get("type") == "done":
                        # å“åº”å®Œæˆ
                        self.synthesis_complete = True
                        logging.info("TTS synthesis completed")
                        ws.close()
                    
                    elif data.get("type") == "error":
                        # é”™è¯¯å¤„ç†
                        error_msg = data.get("message", "Unknown error")
                        logging.error(f"TTS error: {error_msg}")
                        self.synthesis_complete = True
                        
                except Exception as e:
                    logging.error(f"Error processing TTS message: {e}")
            
            def on_error(ws, error):
                logging.error(f"TTS WebSocket error: {error}")
                self.synthesis_complete = True
            
            def on_close(ws, close_status_code, close_msg):
                logging.info("TTS WebSocket connection closed")
                self.synthesis_complete = True
            
            # åˆ›å»ºWebSocketè¿æ¥
            ws = websocket.WebSocketApp(
                self.api_url,
                header=headers,
                on_open=on_open,
                on_message=on_message,
                on_error=on_error,
                on_close=on_close
            )
            
            # åœ¨æ–°çº¿ç¨‹ä¸­è¿è¡ŒWebSocket
            def run_websocket():
                ws.run_forever()
            
            thread = threading.Thread(target=run_websocket)
            thread.daemon = True
            thread.start()
            
            # ç­‰å¾…åˆæˆå®Œæˆ
            timeout = 30  # 30ç§’è¶…æ—¶
            start_time = time.time()
            while not self.synthesis_complete and (time.time() - start_time) < timeout:
                time.sleep(0.1)
            
            if not self.synthesis_complete:
                logging.warning("TTS synthesis timeout")
                return {"audio_data": b"", "performance": {}}
            
            # è®¡ç®—æ€§èƒ½ç»Ÿè®¡
            synthesis_end_time = time.perf_counter()
            first_audio_latency = (self.first_audio_time - self.synthesis_start_time) * 1000.0 if self.first_audio_time else 0
            total_synthesis_time = (synthesis_end_time - self.synthesis_start_time) * 1000.0
            chinese_count = sum(1 for ch in text if "\u4e00" <= ch <= "\u9fff")
            
            performance = {
                "first_audio_ms": first_audio_latency,
                "total_synthesis_ms": total_synthesis_time,
                "chinese_count": chinese_count
            }
            
            return {
                "audio_data": self.audio_data,
                "performance": performance
            }
                
        except Exception as e:
            logging.error(f"Qwen3 TTS Realtime synthesis failed: {e}")
            return {"audio_data": b"", "performance": {}}
    
    def synthesize(self, text: str, voice: str = "Cherry") -> bytes:
        """ä½¿ç”¨Qwen3 TTS Realtimeè¿›è¡Œè¯­éŸ³åˆæˆï¼ˆå…¼å®¹æ€§æ–¹æ³•ï¼‰"""
        result = self.synthesize_streaming(text, voice)
        return result["audio_data"]


class VoiceInterface:
    """è¯­éŸ³æ¥å£ä¸»ç±» - åªæ”¯æŒGummySTTå’Œqwen3-tts-realtime"""
    
    def __init__(self, stt_model: STTModel = None, tts_model: TTSModel = None, voice: str = "Cherry"):
        load_dotenv()
        self.setup_logging()
        
        # åˆå§‹åŒ–STTå’ŒTTS - ç¨‹åºå‘˜å¯ä»¥ä¼ å…¥è‡ªå®šä¹‰æ¨¡å‹
        self.stt = stt_model or self._create_stt()
        self.tts = tts_model or self._create_tts()
        self.voice = voice  # TTSéŸ³è‰²
        
        # éŸ³é¢‘å‚æ•°
        self.chunk = 1024
        self.format = pyaudio.paInt16
        self.channels = 1
        self.rate = 16000
        self.record_seconds = 5  # é»˜è®¤å½•éŸ³5ç§’
        
        self.audio = pyaudio.PyAudio()
    
    def setup_logging(self):
        level = os.getenv("LOG_LEVEL", "INFO").upper()
        logging.basicConfig(level=level, format="%(asctime)s | %(levelname)s | %(message)s")
    
    def _create_stt(self) -> STTModel:
        """åˆ›å»ºSTTæ¨¡å‹ - é»˜è®¤ä½¿ç”¨GummySTT"""
        api_key = os.getenv("DASHSCOPE_API_KEY")
        model = os.getenv("STT_MODEL", "gummy-chat-v1")
        return GummySTT(api_key=api_key, model=model)
    
    def _create_tts(self) -> TTSModel:
        """åˆ›å»ºTTSæ¨¡å‹ - é»˜è®¤ä½¿ç”¨qwen3-tts-flash-realtime"""
        api_key = os.getenv("DASHSCOPE_API_KEY")
        model = os.getenv("TTS_MODEL", "qwen3-tts-flash-realtime")
        return Qwen3TTSRealtime(api_key=api_key, model=model)
    
    def record_audio(self, duration: Optional[int] = None) -> bytes:
        """å½•åˆ¶éŸ³é¢‘"""
        duration = duration or self.record_seconds
        
        print(f"ğŸ¤ å¼€å§‹å½•éŸ³ ({duration}ç§’)...")
        
        stream = self.audio.open(
            format=self.format,
            channels=self.channels,
            rate=self.rate,
            input=True,
            frames_per_buffer=self.chunk
        )
        
        frames = []
        for _ in range(0, int(self.rate / self.chunk * duration)):
            data = stream.read(self.chunk)
            frames.append(data)
        
        stream.stop_stream()
        stream.close()
        
        # å°†éŸ³é¢‘æ•°æ®è½¬æ¢ä¸ºWAVæ ¼å¼
        wav_buffer = io.BytesIO()
        with wave.open(wav_buffer, 'wb') as wf:
            wf.setnchannels(self.channels)
            wf.setsampwidth(self.audio.get_sample_size(self.format))
            wf.setframerate(self.rate)
            wf.writeframes(b''.join(frames))
        
        print("âœ… å½•éŸ³å®Œæˆ")
        return wav_buffer.getvalue()
    
    def transcribe_audio(self, audio_data: bytes) -> str:
        """å°†éŸ³é¢‘è½¬æ¢ä¸ºæ–‡æœ¬"""
        print("ğŸ”„ æ­£åœ¨è¯†åˆ«è¯­éŸ³...")
        start_time = time.perf_counter()
        
        text = self.stt.transcribe(audio_data)
        
        end_time = time.perf_counter()
        print(f"âœ… è¯†åˆ«å®Œæˆ ({end_time - start_time:.1f}ç§’): {text}")
        
        return text
    
    def synthesize_speech(self, text: str) -> bytes:
        """å°†æ–‡æœ¬è½¬æ¢ä¸ºè¯­éŸ³"""
        print("ğŸ”„ æ­£åœ¨åˆæˆè¯­éŸ³...")
        start_time = time.perf_counter()
        
        audio_data = self.tts.synthesize(text, voice=self.voice)
        
        end_time = time.perf_counter()
        print(f"âœ… åˆæˆå®Œæˆ ({end_time - start_time:.1f}ç§’)")
        
        return audio_data
    
    def play_audio_streaming(self, audio_chunk: bytes):
        """æµå¼æ’­æ”¾éŸ³é¢‘ç‰‡æ®µ"""
        try:
            import tempfile
            import subprocess
            
            # ä¿å­˜éŸ³é¢‘ç‰‡æ®µåˆ°ä¸´æ—¶æ–‡ä»¶
            with tempfile.NamedTemporaryFile(suffix=".wav", delete=False) as temp_file:
                temp_file.write(audio_chunk)
                temp_file_path = temp_file.name
            
            # ä½¿ç”¨ç³»ç»Ÿæ’­æ”¾å™¨æ’­æ”¾
            subprocess.run(["aplay", temp_file_path], check=True, capture_output=True)
            
            # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
            os.unlink(temp_file_path)
            
        except Exception as e:
            logging.debug(f"Streaming audio playback failed: {e}")
    
    def play_audio(self, audio_data: bytes):
        """æ’­æ”¾éŸ³é¢‘"""
        print("ğŸ”Š æ­£åœ¨æ’­æ”¾...")
        
        # ç›´æ¥ä½¿ç”¨ç³»ç»Ÿæ’­æ”¾å™¨ï¼Œé¿å…PyAudioçš„é‡‡æ ·ç‡é—®é¢˜
        self._fallback_play_audio(audio_data)
    
    def _fallback_play_audio(self, audio_data: bytes):
        """å¤‡é€‰éŸ³é¢‘æ’­æ”¾æ–¹æ¡ˆ"""
        try:
            import tempfile
            import subprocess
            
            # ä¿å­˜éŸ³é¢‘åˆ°ä¸´æ—¶æ–‡ä»¶
            with tempfile.NamedTemporaryFile(suffix=".wav", delete=False) as temp_file:
                temp_file.write(audio_data)
                temp_file_path = temp_file.name
            
            # ä½¿ç”¨ç³»ç»Ÿæ’­æ”¾å™¨æ’­æ”¾
            print("ğŸ”„ ä½¿ç”¨ç³»ç»Ÿæ’­æ”¾å™¨æ’­æ”¾...")
            subprocess.run(["aplay", temp_file_path], check=True)
            
            # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
            os.unlink(temp_file_path)
            print("âœ… æ’­æ”¾å®Œæˆ")
            
        except Exception as e:
            logging.error(f"Fallback audio playback failed: {e}")
            print(f"âŒ å¤‡é€‰æ’­æ”¾ä¹Ÿå¤±è´¥äº†: {e}")
            print("ğŸ’¡ å»ºè®®ï¼šè¯·æ£€æŸ¥éŸ³é¢‘è®¾å¤‡æˆ–å®‰è£…aplay: sudo apt-get install alsa-utils")
    
    def voice_to_text(self, duration: Optional[int] = None) -> str:
        """å®Œæ•´çš„è¯­éŸ³è½¬æ–‡æœ¬æµç¨‹"""
        audio_data = self.record_audio(duration)
        return self.transcribe_audio(audio_data)
    
    def text_to_voice_streaming(self, text: str) -> dict:
        """å®Œæ•´çš„æµå¼æ–‡æœ¬è½¬è¯­éŸ³æµç¨‹"""
        print("ğŸ”„ æ­£åœ¨æµå¼åˆæˆè¯­éŸ³...")
        
        # ä½¿ç”¨æµå¼åˆæˆ
        result = self.tts.synthesize_streaming(text, voice=self.voice, callback=self.play_audio_streaming)
        
        return result
    
    def text_to_voice(self, text: str):
        """å®Œæ•´çš„æ–‡æœ¬è½¬è¯­éŸ³æµç¨‹"""
        audio_data = self.synthesize_speech(text)
        self.play_audio(audio_data)
    
    def set_voice(self, voice: str):
        """è®¾ç½®TTSéŸ³è‰²"""
        self.voice = voice
        logging.info(f"TTS voice changed to: {voice}")
    
    def get_available_voices(self) -> dict:
        """è·å–å¯ç”¨çš„éŸ³è‰²åˆ—è¡¨ - æ ¹æ®å®˜æ–¹æ–‡æ¡£"""
        return {
            "èŠŠæ‚¦ (Cherry)": "Cherry",
            "æ™¨ç…¦ (Ethan)": "Ethan", 
            "ä¸åƒé±¼ (Nofish)": "Nofish",
            "è©¹å¦®å¼— (Jennifer)": "Jennifer",
            "ç”œèŒ¶ (Ryan)": "Ryan",
            "å¡æ·ç³å¨œ (Katerina)": "Katerina",
            "å¢¨è®²å¸ˆ (Elias)": "Elias",
            "ä¸Šæµ·-é˜¿ç (Jada)": "Jada",
            "åŒ—äº¬-æ™“ä¸œ (Dylan)": "Dylan",
            "å››å·-æ™´å„¿ (Sunny)": "Sunny",
            "å—äº¬-è€æ (Li)": "Li",  # ä¿®æ­£ä¸ºå®˜æ–¹æ–‡æ¡£ä¸­çš„Li
            "é™•è¥¿-ç§¦å· (Marcus)": "Marcus",
            "é—½å—-é˜¿æ° (Roy)": "Roy",
            "å¤©æ´¥-æå½¼å¾— (Peter)": "Peter",
            "ç²¤è¯­-é˜¿å¼º (Rocky)": "Rocky",
            "ç²¤è¯­-é˜¿æ¸… (Kiki)": "Kiki",
            "å››å·-ç¨‹å· (Eric)": "Eric"
        }
    
    def cleanup(self):
        """æ¸…ç†èµ„æº"""
        self.audio.terminate()


def test_voice_interface():
    """æµ‹è¯•è¯­éŸ³æ¥å£"""
    try:
        voice = VoiceInterface()
        
        print("=== è¯­éŸ³æ¥å£æµ‹è¯• ===")
        print("1. æµ‹è¯•è¯­éŸ³è½¬æ–‡æœ¬...")
        text = voice.voice_to_text(duration=3)
        print(f"è¯†åˆ«ç»“æœ: {text}")
        
        if text.strip():
            print("\n2. æµ‹è¯•æ–‡æœ¬è½¬è¯­éŸ³...")
            voice.text_to_voice(text)
        
        voice.cleanup()
        print("\nâœ… æµ‹è¯•å®Œæˆ")
        
    except Exception as e:
        print(f"âŒ æµ‹è¯•å¤±è´¥: {e}")
        logging.exception("Voice interface test failed")


if __name__ == "__main__":
    test_voice_interface()